<!DOCTYPE html>
<html âš¡>
<head>
    <meta charset="utf-8">

    <title>Deep Learning in 100 lines of pure Python</title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1">

    <link rel="shortcut icon" href="../../favicon.ico" type="image/x-icon" />
    <link rel="canonical" href="../index.html" />
    <meta name="referrer" content="no-referrer-when-downgrade" />
    
    <meta property="og:site_name" content="Julian Eisenschlos" />
    <meta property="og:type" content="article" />
    <meta property="og:title" content="Deep Learning in 100 lines of pure Python" />
    <meta property="og:description" content="Can we build a Deep learning framework in plain Python and Numpy? Can we make it compact, clear and extendable? Let&#x27;s set out to explore those ideas and see what we can create!" />
    <meta property="og:url" content="https://eisenjulian.github.io/deep-learning-in-100-lines/" />
    <meta property="og:image" content="https://eisenjulian.github.io/content/images/2019/03/onion.jpg" />
    <meta property="article:published_time" content="2019-03-17T15:33:37.000Z" />
    <meta property="article:modified_time" content="2019-03-25T02:39:27.000Z" />
    <meta property="article:tag" content="Automatic Differentiation" />
    <meta property="article:tag" content="Math" />
    <meta property="article:tag" content="Tutorials" />
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Deep Learning in 100 lines of pure Python" />
    <meta name="twitter:description" content="Can we build a Deep learning framework in plain Python and Numpy? Can we make it compact, clear and extendable? Let&#x27;s set out to explore those ideas and see what we can create!" />
    <meta name="twitter:url" content="https://eisenjulian.github.io/deep-learning-in-100-lines/" />
    <meta name="twitter:image" content="https://eisenjulian.github.io/content/images/2019/03/onion.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Julian Eisenschlos" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="Automatic Differentiation, Math, Tutorials" />
    <meta name="twitter:site" content="@eisenjulian" />
    <meta property="og:image:width" content="640" />
    <meta property="og:image:height" content="360" />
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Julian Eisenschlos",
        "logo": {
            "@type": "ImageObject",
            "url": "https://eisenjulian.github.io/favicon.ico",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Julian Eisenschlos",
        "image": {
            "@type": "ImageObject",
            "url": "https://eisenjulian.github.io/content/images/2019/03/perfil-square.jpeg",
            "width": 710,
            "height": 710
        },
        "url": "https://eisenjulian.github.io/author/julian/",
        "sameAs": []
    },
    "headline": "Deep Learning in 100 lines of pure Python",
    "url": "https://eisenjulian.github.io/deep-learning-in-100-lines/",
    "datePublished": "2019-03-17T15:33:37.000Z",
    "dateModified": "2019-03-25T02:39:27.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://eisenjulian.github.io/content/images/2019/03/onion.jpg",
        "width": 640,
        "height": 360
    },
    "keywords": "Automatic Differentiation, Math, Tutorials",
    "description": "Can we build a Deep learning framework in plain Python and Numpy? Can we make it compact, clear and extendable? Let&#x27;s set out to explore those ideas and see what we can create!",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://eisenjulian.github.io/"
    }
}
    </script>

    <meta name="generator" content="Ghost 2.18" />
    <link rel="alternate" type="application/rss+xml" title="Julian Eisenschlos" href="../../rss/index.html" />

    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,600,400" />
    <style amp-custom>html{font-family:sans-serif;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}article,aside,details,figcaption,figure,footer,header,main,menu,nav,section,summary{display:block}audio,canvas,progress,video{display:inline-block;vertical-align:baseline}audio:not([controls]){display:none;height:0}[hidden],template{display:none}a{background-color:transparent}a:active,a:hover{outline:0}abbr[title]{border-bottom:1px dotted}b,strong{font-weight:bold}dfn{font-style:italic}h1{margin:0.67em 0;font-size:2em}mark{background:#ff0;color:#000}small{font-size:80%}sub,sup{position:relative;vertical-align:baseline;font-size:75%;line-height:0}sup{top:-0.5em}sub{bottom:-0.25em}img{border:0}amp-img{border:0}svg:not(:root){overflow:hidden}figure{margin:1em 40px}hr{box-sizing:content-box;height:0}pre{overflow:auto}code,kbd,pre,samp{font-family:monospace, monospace;font-size:1em}button,input,optgroup,select,textarea{margin:0;color:inherit;font:inherit}button{overflow:visible}button,select{text-transform:none}button,html input[type="button"],input[type="reset"],input[type="submit"]{cursor:pointer;-webkit-appearance:button}button[disabled],html input[disabled]{cursor:default}button::-moz-focus-inner,input::-moz-focus-inner{padding:0;border:0}input{line-height:normal}input[type="checkbox"],input[type="radio"]{box-sizing:border-box;padding:0}input[type="number"]::-webkit-inner-spin-button,input[type="number"]::-webkit-outer-spin-button{height:auto}input[type="search"]{-webkit-appearance:textfield}input[type="search"]::-webkit-search-cancel-button,input[type="search"]::-webkit-search-decoration{-webkit-appearance:none}fieldset{margin:0 2px;padding:0.35em 0.625em 0.75em;border:1px solid #c0c0c0}legend{padding:0;border:0}textarea{overflow:auto}optgroup{font-weight:bold}table{border-spacing:0;border-collapse:collapse}td,th{padding:0}html{max-height:100%;height:100%;font-size:62.5%;-webkit-tap-highlight-color:rgba(0, 0, 0, 0)}body{max-height:100%;height:100%;color:#3a4145;background:#f4f8fb;letter-spacing:0.01rem;font-family:"Merriweather", serif;font-size:1.8rem;line-height:1.75em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"kern" 1;-moz-font-feature-settings:"kern" 1;-o-font-feature-settings:"kern" 1}::-moz-selection{background:#d6edff}::selection{background:#d6edff}h1,h2,h3,h4,h5,h6{margin:0 0 0.3em 0;color:#2e2e2e;font-family:"Open Sans", sans-serif;line-height:1.15em;text-rendering:geometricPrecision;-webkit-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1;-moz-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1;-o-font-feature-settings:"dlig" 1, "liga" 1, "lnum" 1, "kern" 1}h1{text-indent:-2px;letter-spacing:-1px;font-size:2.6rem}h2{letter-spacing:0;font-size:2.4rem}h3{letter-spacing:-0.6px;font-size:2.1rem}h4{font-size:1.9rem}h5{font-size:1.8rem}h6{font-size:1.8rem}a{color:#4a4a4a}a:hover{color:#111}p,ul,ol,dl{margin:0 0 2.5rem 0;font-size:1.5rem;text-rendering:geometricPrecision;-webkit-font-feature-settings:"liga" 1, "onum" 1, "kern" 1;-moz-font-feature-settings:"liga" 1, "onum" 1, "kern" 1;-o-font-feature-settings:"liga" 1, "onum" 1, "kern" 1}ol,ul{padding-left:2em}ol ol,ul ul,ul ol,ol ul{margin:0 0 0.4em 0;padding-left:2em}dl dt{float:left;clear:left;overflow:hidden;margin-bottom:1em;width:180px;text-align:right;text-overflow:ellipsis;white-space:nowrap;font-weight:700}dl dd{margin-bottom:1em;margin-left:200px}li{margin:0.4em 0}li li{margin:0}hr{display:block;margin:1.75em 0;padding:0;height:1px;border:0;border-top:#efefef 1px solid}blockquote{box-sizing:border-box;margin:1.75em 0 1.75em 0;padding:0 0 0 1.75em;border-left:#4a4a4a 0.4em solid;-moz-box-sizing:border-box}blockquote p{margin:0.8em 0;font-style:italic}blockquote small{display:inline-block;margin:0.8em 0 0.8em 1.5em;color:#ccc;font-size:0.9em}blockquote small:before{content:"\2014 \00A0"}blockquote cite{font-weight:700}blockquote cite a{font-weight:normal}mark{background-color:#fdffb6}code,tt{padding:1px 3px;border:#e3edf3 1px solid;background:#f7fafb;border-radius:2px;white-space:pre-wrap;font-family:Inconsolata, monospace, sans-serif;font-size:0.85em;font-feature-settings:"liga" 0;-webkit-font-feature-settings:"liga" 0;-moz-font-feature-settings:"liga" 0}pre{overflow:auto;box-sizing:border-box;margin:0 0 1.75em 0;padding:10px;width:100%;border:#e3edf3 1px solid;background:#f7fafb;border-radius:3px;white-space:pre;font-family:Inconsolata, monospace, sans-serif;font-size:0.9em;-moz-box-sizing:border-box}pre code,pre tt{padding:0;border:none;background:transparent;white-space:pre-wrap;font-size:inherit}kbd{display:inline-block;margin-bottom:0.4em;padding:1px 8px;border:#ccc 1px solid;background:#f4f4f4;border-radius:4px;box-shadow:0 1px 0 rgba(0, 0, 0, 0.2), 0 1px 0 0 #fff inset;color:#666;text-shadow:#fff 0 1px 0;font-size:0.9em;font-weight:700}table{box-sizing:border-box;margin:1.75em 0;max-width:100%;width:100%;background-color:transparent;-moz-box-sizing:border-box}table th,table td{padding:8px;border-top:#efefef 1px solid;vertical-align:top;text-align:left;line-height:20px}table th{color:#000}table caption + thead tr:first-child th,table caption + thead tr:first-child td,table colgroup + thead tr:first-child th,table colgroup + thead tr:first-child td,table thead:first-child tr:first-child th,table thead:first-child tr:first-child td{border-top:0}table tbody + tbody{border-top:#efefef 2px solid}table table table{background-color:#fff}table tbody > tr:nth-child(odd) > td,table tbody > tr:nth-child(odd) > th{background-color:#f6f6f6}table.plain tbody > tr:nth-child(odd) > td,table.plain tbody > tr:nth-child(odd) > th{background:transparent}iframe,amp-iframe,.fluid-width-video-wrapper{display:block;margin:1.75em 0}.fluid-width-video-wrapper iframe,.fluid-width-video-wrapper amp-iframe{margin:0}textarea,select,input{margin:0 0 5px 0;padding:6px 9px;width:260px;outline:0;border:#e7eef2 1px solid;background:#fff;border-radius:4px;box-shadow:none;font-family:"Open Sans", sans-serif;font-size:1.6rem;line-height:1.4em;font-weight:100;-webkit-appearance:none}textarea{min-width:250px;min-height:80px;max-width:340px;width:100%;height:auto}input[type="text"]:focus,input[type="email"]:focus,input[type="search"]:focus,input[type="tel"]:focus,input[type="url"]:focus,input[type="password"]:focus,input[type="number"]:focus,input[type="date"]:focus,input[type="month"]:focus,input[type="week"]:focus,input[type="time"]:focus,input[type="datetime"]:focus,input[type="datetime-local"]:focus,textarea:focus{outline:none;outline-width:0;border:#bbc7cc 1px solid;background:#fff}select{width:270px;height:30px;line-height:30px}.clearfix:before,.clearfix:after{content:" ";display:table}.clearfix:after{clear:both}.clearfix{zoom:1}.main-header{position:relative;display:table;overflow:hidden;box-sizing:border-box;width:100%;height:50px;background:#5ba4e5 no-repeat center center;background-size:cover;text-align:left;-webkit-box-sizing:border-box;-moz-box-sizing:border-box}.content{background:#fff;padding-top:15px}.blog-title,.content{margin:auto;max-width:600px}.blog-title a{display:block;padding-right:16px;padding-left:16px;height:50px;color:#fff;text-decoration:none;font-family:"Open Sans", sans-serif;font-size:16px;line-height:50px;font-weight:600}.post{position:relative;margin-top:0;margin-right:16px;margin-left:16px;padding-bottom:0;max-width:100%;border-bottom:#ebf2f6 1px solid;word-wrap:break-word;font-size:0.95em;line-height:1.65em}.post-header{margin-bottom:1rem}.post-title{margin-bottom:0}.post-title a{text-decoration:none}.post-meta{display:block;margin:3px 0 0 0;color:#9eabb3;font-family:"Open Sans", sans-serif;font-size:1.3rem;line-height:2.2rem}.post-meta a{color:#9eabb3;text-decoration:none}.post-meta a:hover{text-decoration:underline}.post-meta .author{margin:0;font-size:1.3rem;line-height:1.3em}.post-date{display:inline-block;text-transform:uppercase;white-space:nowrap;font-size:1.2rem;line-height:1.2em}.post-image{margin:0;padding-top:3rem;padding-bottom:30px;border-top:1px #E8E8E8 solid}.post-content amp-img,.post-content amp-anim{position:relative;left:50%;display:block;padding:0;min-width:0;max-width:112%;width:calc(100% + 32px);height:auto;transform:translateX(-50%);-webkit-transform:translateX(-50%);-ms-transform:translateX(-50%)}.footnotes{font-size:1.3rem;line-height:1.6em;font-style:italic}.footnotes li{margin:0.6rem 0}.footnotes p{margin:0}.footnotes p a:last-child{text-decoration:none}.site-footer{position:relative;margin:0 auto 20px auto;padding:1rem 15px;max-width:600px;color:rgba(0,0,0,0.5);font-family:"Open Sans", sans-serif;font-size:1.1rem;line-height:1.75em}.site-footer a{color:rgba(0,0,0,0.5);text-decoration:none;font-weight:bold}.site-footer a:hover{border-bottom:#bbc7cc 1px solid}.poweredby{display:block;float:right;width:45%;text-align:right}.copyright{display:block;float:left;width:45%}</style>

    <style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
    <script async src="https://cdn.ampproject.org/v0.js"></script>

    <script async custom-element="amp-anim" src="https://cdn.ampproject.org/v0/amp-anim-0.1.js"></script>

</head>

<body class="amp-template">
    <header class="main-header">
        <nav class="blog-title">
            <a href="../../index.html">Julian Eisenschlos</a>
        </nav>
    </header>

    <main class="content" role="main">
        <article class="post">

            <header class="post-header">
                <h1 class="post-title">Deep Learning in 100 lines of pure Python</h1>
                <section class="post-meta">
                    <p class="author">by <a href="../../author/julian/index.html">Julian Eisenschlos</a></p>
                    <time class="post-date" datetime="2019-03-17">2019-03-17</time>
                </section>
            </header>
            <figure class="post-image">
                <amp-img src="https://eisenjulian.github.io/content/images/2019/03/onion.jpg" width="600" height="400" layout="responsive"></amp-img>
            </figure>
            <section class="post-content">

                <p><em>Can we build a Deep learning framework in pure Python and Numpy? Can we make it compact, clear and extendable? Let's set out to explore those ideas and see what we can create!</em></p><hr></hr><p>In today's day and age there are multiple frameworks to choose from, with various important features such as auto-differentiation, graph-based optimized computation and hardware acceleration. It's easy to take those features for granted, but every once in a while peeking under the hood can teach us what makes things work and what doesn't.</p><p>What we'll cover:</p><ul><li>Automatic back-propagation</li><li>How to implement a few basic layers</li><li>How to create a training loop</li></ul><p>The design choices are heavily based on <a href="https://github.com/explosion/thinc">Thinc</a>'s Deep Learning library, since they came up with the smart idea of using Â functions, closures, and the stack to share and keep track of intermediate results while calculating gradients. This post is also inspired by Jeremy Howard's great <a href="https://pytorch.org/tutorials/beginner/nn_tutorial.html">PyTorch tutorial</a>, but taking it one more step towards the bottom getting rid of <code>autograd</code>.</p><h2 id="notation">Notation</h2><p>I will try to make the language here as unloaded as possible, but some symbols are hard to avoid:</p><ul><li>For two functions $f$ and $g$, $f \circ g$ is their composition, so that <br />$(f \circ g)(x) = f(g(x))$</li><li>Let $f:\mathbb{R}^n\to\mathbb{R}$ and $x\in\mathbb{R}^n$, then the gradient $\nabla f (x)$ is the $n$-dimensional row vector of partial derivatives $\frac{\partial f}{\partial_j }(x)$</li><li>If $f:\mathbb{R}^n\to\mathbb{R}^m$ and $x\in\mathbb{R}^n$ then the Jacobian matrix is an $m\times n$ matrix that generalizes the gradient such that row $i$ is the gradient of $f$ restricted to the $i$ coordinate:<br />$Jf(x)_{ij} = \frac{\partial f_i}{\partial_j}(x)$</li><li>When the input of $f:V\times W \to\ U$ consists of two sets of parameters we will often want to only look at the Jacobian matrix (or gradient) with respect to one half of the parameters. We write $J_V f$ (or $\nabla_V f$) to denote the restriction to the columns that correspond to the parameters in $V$, assuming the part in $W$ is fixed.</li></ul><h2 id="the-chain-rule">The chain rule</h2><p>If we have two vector spaces $V$ and $W$ and two differentiable functions $f:V\to W$ and $g:W\to\mathbb{R}$ we have that if $v\in V$ and $f(v) = w$ we can get the gradient of $\nabla g \circ f$ as a matrix product as follows:</p><p>$\nabla g \circ f(v) = \nabla g(w) \cdot Jf(v)$</p><p>That's the chain rule in all its glory. The back-propagation algorithm, originally described in the 60's and 70's is the application of the chain rule to calculate gradients of a real function with respect of its various parameters.</p><p>Keep in mind that our end goal is to find a minimum (hopefully global) of a function by taking steps in the opposite direction of said gradient, because locally at least this will take it downwards. This is how it looks when we have two parameters to optimize.</p><figure class="kg-card kg-image-card kg-card-hascaption"><figcaption>Source: <a href="https://jed-ai.github.io/py1_gd_animation/">7 Simple Steps To Visualize And Animate The Gradient Descent Algorithm</a></figcaption></figure><h2 id="reverse-mode-differentiation">Reverse mode differentiation</h2><p>If we compose many functions $h Â = g \circ f_1\circ f_2 \cdots f_n$, instead of just two, then we can apply that formula repeatedly and conclude that</p><p>$\nabla f(v) = \nabla g \cdot Jf_1 \cdot Jf_2 \cdots Jf_n$</p><p>In practice we will calculate the full gradient by starting with the row vector $\nabla g$ and multiplying by $Jf_i$ on the right one at a time. This operation is sometimes referred as <em>VJP</em>, or <em>Vector-Jacobian Product</em>. The whole process is known as <strong>reverse mode</strong> differentiation, because we gradually compute the gradient working from the end $g$ backward through $g\circ f_1$, $g\circ f_1 \circ f_2$, etc. </p><p>In contrast, the alternative <strong>forward mode</strong> uses <em>Jacobian-Vector Products</em> (or <em>JVP</em>), which starts with a column vector and multiplies by $Jf_i$ on the left. If the initial vector is the canonical vector with $1$ at position $j$ then the first product is the column $\frac{\partial}{\partial_j}f_n$ and as we continue we are computing the derivative with respect to the parameter $x_j$ of the composition of the last $k$ functions<br />$\frac{\partial}{\partial_j} f_{n-k+1}\cdots f_{n-1}\circ f_n$<br />This will be less efficient since we would have to do it for every $j$ to get the full gradient, and there can be millions of parameters, while in reverse mode we only do it once. </p><p>This sounds like a lot of high-dimensional matrix products, but the trick is that very often the Jacobian matrixes will be sparse, <a href="https://en.wikipedia.org/wiki/Block_matrix">block</a> or even diagonal and, because we only care about the result of multiplying it by a row vector on the left, we wont't need to compute or store it explicitly</p><h2 id="link-to-deep-neural-networks">Link to deep neural networks</h2><p>In the typical setting for supervised machine learning we have a big complex function that takes in a tensor of numerical features for our labelled samples, and several tensors that correspond to weights that characterize the model.</p><p>The loss, as a scalar function of both the samples and weights, is a measure of how far the model output was from the expected labels. We want to minimize it to find the most suitable weights. In deep learning, this function is expressed as a composition of simpler functions, each of which is easy to differentiate. All of them but the last are what we refer to as layers, and each layer usually has two sets of parameters: the inputs (which can be the output of the previous layer) and the weights. </p><p>The last function is the loss metric, which also has two sets of parameters: model output $y$ and the true labels $\hat{y}$, but the latter is fixed, so we will never need to get the gradient with respect to $\hat{y}$. For example, if the loss metric $L$ is the mean square error then $\nabla L$ is $2\ Â \text{avg}(y - \hat{y})$. The gradient of the loss will be the starting row vector to apply reverse mode differentiation.</p><h2 id="autograd">Autograd</h2><p>The ideas behind Automatic Differentiation are quite mature. It can be done in runtime or during compilation, which can have dramatic impact on performance. I recommend the <a href="https://github.com/HIPS/autograd">HIPS autograd</a> Python package for a thorough explanation of some of the concepts. </p><p>The core idea, however, is always the same, and we have known it ever since we started computing derivatives in school. If we can keep track of the graph of computations that resulted in the final scalar output and we know how to differentiate each simple operation (sums and products, powers, exponentials and logarithms, ...), we can recover the gradient of the output.</p><p>Let's say that we have some intermediate linear layer $f$ which is characterized by a matrix multiplication (let's leave the bias out for a sec):</p><p>$y = f(x, w) = x\cdot w$</p><p>In order to tune the values of $w$ with gradient descent, we need to compute the gradient $\nabla_w L \circ f$. Here we are overloading $L$ to mean the loss plus all the layers after $f$. </p><blockquote>The contract that any layer has to satisfy is the following: if Â I tell you the gradient of the loss with respect of your outputs, you can tell me the gradient with respect of your inputs, which are in turn the previous layer outputs.</blockquote><p>Now we can apply the chain rule twice: for the gradient with respect to $w$ we get that </p><p>$\nabla_w L \circ f = \nabla_y L \cdot J_w f = \nabla_y L \cdot x^t $ </p><p>and with respect to $x$</p><p>$\nabla_x L \circ f = \nabla_y L \cdot J_x f = \nabla_y L \cdot w$ </p><p>So we can both pass a gradient backward to satisfy the contract and update the internal layer weights to optimize the loss, and that's it!</p><h2 id="implementation-time">Implementation time</h2><p>We can start with a class that encapsulates a tensor and its gradients</p><pre><code class="language-python">class Parameter():
  def __init__(self, tensor):
    self.tensor = tensor
    self.gradient = np.zeros_like(self.tensor)
</code></pre>
<p>Now we can create the layer class, the key idea is that in forward pass we return both the layer output and function that can receive the gradient of loss with respect to the outputs can return the gradient with respect of the inputs, updating the weight gradients in the process.</p><p>The training process will then have three steps, calculate the forward step, then the backwards steps accumulates the gradients, and finally updating the weights. Itâ€™s important to this at the end, since weights can be reused in multiple layers and we donâ€™t want to mutate the weights before time.</p><pre><code class="language-python">class Layer:
  def __init__(self):
    self.parameters = []

  def forward(self, X):
    """
    Override me! A simple no-op layer, it passes forward the inputs
    """
    return X, lambda D: D

  def build_param(self, tensor):
    """
    Creates a parameter from a tensor, and saves a reference for the update step
    """
    param = Parameter(tensor)
    self.parameters.append(param)
    return param

  def update(self, optimizer):
    for param in self.parameters: optimizer.update(param)
</code></pre>
<p>It's standard to delegate the job of updating the parameters to an optimizer, which receives an instance of a parameter after every batch. The simplest and most known optimization method out there is the mini-batch stochastic gradient descent</p><pre><code class="language-python">class SGDOptimizer():
  def __init__(self, lr=0.1):
    self.lr = lr

  def update(self, param):
    param.tensor -= self.lr * param.gradient
    param.gradient.fill(0)
</code></pre>
<p>Under this framework, the linear layer looks like this:</p><pre><code class="language-python">class Linear(Layer):
  def __init__(self, inputs, outputs):
    super().__init__()
    tensor = np.random.randn(inputs, outputs) * np.sqrt(1 / inputs)
    self.weights = self.build_param(tensor)
    self.bias = self.build_param(np.zeros(outputs))

  def forward(self, X):
    def backward(D):
      self.weights.gradient += X.T @ D
      self.bias.gradient += D.sum(axis=0)
      return D @ self.weights.tensor.T
    return X @ self.weights.tensor +  self.bias.tensor, backward
</code></pre>
<p>Now, the next most used types of layers are activations, which are non-linear point-wise functions. The Jacobian of a point-wise function is diagonal, which means that when multiplied by the gradient it also acts a point-wise multiplication. </p><pre><code class="language-python">class ReLu(Layer):
  def forward(self, X):
    mask = X &gt; 0
    return X * mask, lambda D: D * mask
</code></pre>
<p>Now that I have we have two kinds of layers, we want to compose them and make sure that backward propagation works as expected. As we traverse the layers and get the successive outputs we can save the <code>backward</code> functions in a list that will be used in the reverse order, to get all the way to gradient with respect to the first layer inputs and return it. This is were the magic happens:</p><pre><code class="language-python">class Sequential(Layer):
  def __init__(self, *layers):
    super().__init__()
    self.layers = layers
    for layer in layers:
      self.parameters.extend(layer.parameters)

  def forward(self, X):
    backprops = []
    Y = X
    for layer in self.layers:
      Y, backprop = layer.forward(Y)
      backprops.append(backprop)
    def backward(D):
      for backprop in reversed(backprops): 
        D = backprop(D)
      return D
    return Y, backward
</code></pre>
<p>As we mentioned earlier, we will need a way to calculate the loss function associated with a batch of samples, and its gradient. One example would be <em>MSE</em> loss, typically used in regression problems, and it can be implemented in this manner:</p><pre><code class="language-python">def mse_loss(Yp, Yt):
  diff = Yp - Yt
  return np.square(diff).mean(), 2 * diff / len(diff)
</code></pre>
<p>Almost there now, we have two types of layers and a way to combine them, so how does the training loop look like. We can use an API similar to <code>scikit-learn</code> or <code>keras</code>.</p><pre><code class="language-python">class Learner():
  def __init__(self, model, loss, optimizer):
    self.model = model
    self.loss = loss
    self.optimizer = optimizer

  def fit_batch(self, X, Y):
    Y_, backward = self.model.forward(X)
    L, D = self.loss(Y_, Y)
    backward(D)
    self.model.update(self.optimizer)
    return L

  def fit(self, X, Y, epochs, bs):
    losses = []
    for epoch in range(epochs):
      p = np.random.permutation(len(X))
      X, Y = X[p], Y[p]
      loss = 0.0
      for i in range(0, len(X), bs):
        loss += self.fit_batch(X[i:i + bs], Y[i:i + bs])
      losses.append(loss)
      print('Epoch', epoch, '\tLoss', loss)
    return losses
</code></pre>
<p>And that is all, if you were keeping track, we even have a few lines of code to spare. </p><h2 id="but-does-it-work">But does it work?</h2><p>Thought you would never ask, we can start testing with some synthetic data.</p><pre><code class="language-python">X = np.random.randn(100, 10)
w = np.random.randn(10, 1)
b = np.random.randn(1)
Y = X @ W + B

model = Linear(10, 1)
learner = Learner(model, mse_loss, SGDOptimizer(lr=0.05))
learner.fit(X, Y, epochs=10, bs=10)
</code></pre>
<figure class="kg-card kg-image-card kg-card-hascaption"><figcaption>Training loss in 10 epochs</figcaption></figure><p>We can also check that the learned weights coincide with the true ones</p><pre><code class="language-python">print(np.linalg.norm(m.weights.tensor - W), (m.bias.tensor - B)[0])
&gt; 1.848553648022619e-05 5.69305886743976e-06
</code></pre>
<p>OK, so that was easy, but let's come up with a non-linear dataset, how about $y = x_1 x_2$. Here we go:</p><p></p><h2 id="wrapping-up">Wrapping Up</h2><p>I hope you have found this educative, we only defined two types of layers and one loss function, so there's much more to be done. In a follow up post we will implement binary cross entropy loss as well as other non-linear activations to start building more expressive models. Stay tuned...</p><p>Reach out on Twitter at <a>@eisenjulian</a> for questions and requests. Thanks for reading!</p><h2 id="references">References</h2><p>[1] Thinc Deep Learnign Library <a href="https://github.com/explosion/thinc">https://github.com/explosion/thinc</a><br />[2] PyTorch Tutorial <a href="https://pytorch.org/tutorials/beginner/nn_tutorial.html">https://pytorch.org/tutorials/beginner/nn_tutorial.html</a><br />[3] HIPS Autograd <a href="https://github.com/HIPS/autograd">https://github.com/HIPS/autograd</a><br /></p>

            </section>

        </article>
    </main>
    <footer class="site-footer clearfix">
        <section class="copyright"><a href="../../index.html">Julian Eisenschlos</a> &copy; 2019</section>
        <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
    </footer>
</body>
</html>
